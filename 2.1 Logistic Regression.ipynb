{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### 1. Model\n",
    "- Aim: we want to know the probability for $Y=1$, given data $X$\n",
    "$$ P(Y=1|X) = \\pi(X) \\in [0,1]$$ \n",
    "since we only have $X,Y$ as the inputs, we want to use $X$ to calculate the probability, that is, \n",
    "$$ P(Y=1|X) = z(\\mathbf{W}^T\\mathbf{X}) $$\n",
    ", where function $$f = z(X) \\in [0,1]$$\n",
    "or we can let \n",
    "$$g(P(Y=1|X)) = g(\\pi(X)) = \\mathbf{W}^T\\mathbf{X}$$,\n",
    "where function $$f = g(X) \\in [-\\infty,\\infty]$$\n",
    "- Let $g(X) = log(\\frac{X}{1-X})$ to make it $\\in [-\\infty,\\infty]$,\n",
    "$$ log(\\frac{P(Y=1|X)}{1-P(Y=1|X)}) = \\frac{P(Y=1|X)}{P(Y=0|X)} = \\mathbf{W}^T\\mathbf{X} $$\n",
    "solve the equations and get:\n",
    "$$ P(Y=1|X) = \\frac{e^{\\mathbf{W}^T\\mathbf{X}}}{1+e^{\\mathbf{W}^T\\mathbf{X}}} = \\frac{1}{1+e^{-\\mathbf{W}^T\\mathbf{X}}}$$\n",
    "$$ P(Y=0|X) = \\frac{1}{1+e^{\\mathbf{W}^T\\mathbf{X}}} $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2. Strategy\n",
    "Different from minimizing the loss function, here we maximize the likelihood function to get the optimal model:\n",
    "- Likelihood function:\n",
    "$$ L(\\mathbf{W}) = \\prod_{i=1}^n (P(Y=1|X_{i}))^{y_{i}} (1-P(Y=1|X_{i}))^{1-y_{i}} $$\n",
    "To solve the function in an easier way, do the log transformation:\n",
    "$$ L(\\mathbf{W}) = \\sum_{i=1}^n (y_{i}log(P(Y=1|X_{i})) + (1-y_{i})log (1-P(Y=1|X_{i})))$$\n",
    "$$ L(\\mathbf{W}) = \\sum_{i=1}^n y_{i} (log\\frac{P(Y=1|X_{i})}{1-P(Y=1|X_{i})} + log(1-P(Y=1|X_{i})))$$\n",
    "$$ L(\\mathbf{W}) = \\sum_{i=1}^n y_{i} (log \\mathbf{W}^T\\mathbf{X} - log (1+e^{\\mathbf{W}^T\\mathbf{X}}))$$\n",
    "- Optimization problem:\n",
    "$$ \\max L(\\hat{\\mathbf{W}}) = \\max \\sum_{i=1}^n y_{i} (log \\hat{\\mathbf{W}}^T\\mathbf{X} - log (1+e^{\\hat{\\mathbf{W}}^T\\mathbf{X}}))$$\n",
    "- The optimal model for X:\n",
    "$$ P(Y=1|X) = \\frac{e^{\\hat{\\mathbf{W}}^T\\mathbf{X}}}{1+e^{\\hat{\\mathbf{W}}^T\\mathbf{X}}} = \\frac{1}{1+e^{-\\hat{\\mathbf{W}}^T\\mathbf{X}}}$$\n",
    "$$ P(Y=0|X) = \\frac{1}{1+e^{\\hat{\\mathbf{W}}^T\\mathbf{X}}} $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3. Algorithm\n",
    "- How to solve the optimization problem: gradient ascent or descent\n",
    "- Gradient descent: Convert the optimization problem to a minimization problem for $-L(\\mathbf{W})$\n",
    "![alt text](images/2.1.1.png)\n",
    "![alt text](images/2.1.2.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 4. Multiclass classification\n",
    "- multi-nominal logistic regression model\n",
    "https://thinkgamer.blog.csdn.net/article/details/85209496?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&dist_request_id=1619621304019_30327&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "$$\\frac{\\partial l}{\\partial w_{0}}\\ =\\ \\sum_{i=1}^n\\ \\frac{y_{i}}{\\sigma (z_{i}}\\ -\\ \\frac{1\\ -\\ y_{i}}{1-\\sigma (z_{i}}\\ \\frac{\\partial}{\\partial w_{0}}\\ \\sigma (z_{i})$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "$$=\\ \\sum_{i=1}^n\\ \\frac{y_{i}\\ -\\ \\sigma (z_{i})}{\\sigma (z_{i})(1-\\ \\sigma (z_{i})}\\ \\sigma (z_{i})(1-\\ \\sigma (z_{i})$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "$$ \\frac{1}{n} \\sum_{i=1}^n (y_{i}-f(x_{i}))^2 $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "$$ "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}