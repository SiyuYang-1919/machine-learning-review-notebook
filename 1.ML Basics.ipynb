{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Basics of ML algorithms\n",
    "## 1. Definition: \n",
    "- ML algorithms build models based on sample data, know as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.\n",
    "\n",
    "## 2. Object:\n",
    "- Data:\n",
    "\n",
    "## 3. Aim:\n",
    "- Consider which model should be learnt and how to learn models to achieve accurate prediction and analysis with highest possible efficiency.\n",
    "\n",
    "## 4. Process:\n",
    "![Alt text](images/1-1.png)\n",
    "- 1. Get a limited training set;\n",
    "- 2. Confirm the hypothesis space (a space including all the possible models);\n",
    "- 3. Make the learining strategy or the standard to choose a model；\n",
    "- 4. Use algorithms to solve the optimal model；\n",
    "- 5. Choose the optimal model；\n",
    "- 6. Use the model to analyze or predict new data.\n",
    "\n",
    "## 5. Basic Categories: \n",
    "### 5.1 Supervised and Unsupervised model:\n",
    "#### Supervised\n",
    "- learning predictive models from labelled data.\n",
    "![Alt text](images/1-2.png)\n",
    ", where $y_{N+1} = arg max_{y}\\hat{P}(y|x_{N+1})$ or $y_{N+1} = \\hat{f}(x_{N+1})$\n",
    "#### Unsupervised\n",
    "- learning predictive models from unlabelled data.\n",
    "![Alt text](images/1-3.png)\n",
    "- Reinforcement\n",
    "- Semi-supervised learning\n",
    "- Active learning\n",
    "\n",
    "### 5.2 Probabilistic and deterministic model:\n",
    "- Main difference is in the inner structure: a probabilistic model can be expressed as joint probability distribution whereas a non-probabilistic model often cannnot. \n",
    "- Logistics model can be viewed as both\n",
    "#### Probabilistic model:\n",
    "- $P(y|x)$ or $P(z|x)$, $P(x|z)$\n",
    "- Decision trees; naive bayes; GMM\n",
    "#### Deterministic model:\n",
    "- $y = f(x)$\n",
    "- SVM, KNN, AdaBoost, K-means, neural networks\n",
    "\n",
    "### 5.3 Parametric and non-parametric model:\n",
    "- Whether the dimension of a model is fixed and limited\n",
    "- P: Naive bayes, logistics regression, k-means, GMM\n",
    "- NP: DT, SVM, AdaBoost, KNN\n",
    "\n",
    "### 5.4 Bayesian learning and kernel method:\n",
    "#### Bayesian learning\n",
    "- Calculate the probability of a model given certain data or posterior probability. \n",
    "![Alt text](images/1-4.png)\n",
    "#### Kernal method\n",
    "- Kernel SVM, PCA, and k-means\n",
    "![Alt text](images/1-5.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6. Three elements of machine learning\n",
    "### 6.1 model\n",
    "- for supervised learning, model is the conditional probability distribution and decision function\n",
    "- hypothesis space for decision functions:\n",
    "$$ F = {f|Y=f_{\\theta}(X),\\theta \\in R^{n}} $$\n",
    "- hypothesis sapce for conditional probability distribution:\n",
    "$$ F = {P|P(Y|X),\\theta \\in R^{n}} $$\n",
    "### 6.2 strategy\n",
    "- according to what standards to learn or choose the optimal model\n",
    "#### Loss (cost) function and risk function (expected loss):\n",
    "- Loss(cost) function:\n",
    "  - 0-1 loss function\n",
    "  \n",
    "  $ L(Y,f(X)) = \n",
    "  \\begin{cases}\n",
    "  1, Y!=f(X)\\\\\n",
    "  0, Y=f(X)\n",
    "  \\end{cases}$\n",
    "\n",
    "  - quadratic loss function\n",
    "  $$  L(Y,f(X)) = (Y-f(X))^2 $$\n",
    "  - absolute loss function\n",
    "  $$ L(Y,f(X)) = |Y-f(X)| $$\n",
    "  - logarithmic loss function\n",
    "  $$ L(Y,P(Y|X)) = -log P(Y|X) $$\n",
    "\n",
    "- Risk function:\n",
    "$ R_exp(f) = E_{p}[L(Y,f(X))]\n",
    "= \\int_{x\\text{x}y} L(y,f(x))P(x,y) \\,{\\rm d}x{\\rm d}y $\n",
    "\n",
    "However, we do not know P(X,Y), but can only get empirical loss based on given training data.\n",
    "\n",
    "$ R_emp(f) = \\frac{1}{N} \\sum_{i=1}^N L(y_{i},f(x_{i})) $\n",
    "\n",
    "\n",
    "#### Minimization strategy\n",
    "- ERM(empirical risk minimization)\n",
    "- SRM(structural risk minimization)\n",
    "### 6.3 algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}