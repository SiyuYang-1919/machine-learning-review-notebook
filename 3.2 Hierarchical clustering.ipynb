{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### 1. Two methods of hierarchical clustering\n",
    "- Agglomerative (or bottom-up): start with singletons, merge by some criterions; details in section 2\n",
    "- Divisive (or top-down): start with all items in one cluster, split recursively\n",
    "  - Hierarchical K-means: run K-means algorithm on the original data and get K clusters, then for each cluster, run K-means again\n",
    "  - Example (when K=2):\n",
    "  ![alt text](images/3.2.3.png)  \n",
    "  ![alt text](images/3.2.4.png)  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2. Three elements of agglomerative clustering\n",
    "- Distance and similarity\n",
    "- Agoolomerative rules\n",
    "- Stopping condition\n",
    "![Alt text](images/3.2.1.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3. Example\n",
    "Given the Euclidean distance matrix, use agoolomerative hierarchical clustering method to do the clustering:\n",
    "$$D = [d_{ij}]_{5x5} = $$\n",
    "$$\n",
    " \\left[\n",
    " \\begin{matrix}\n",
    "   0 & 7 & 2 & 9 & 3 \\\\\n",
    "   7 & 0 & 5 & 4 & 6 \\\\\n",
    "   2 & 5 & 0 & 8 & 1 \\\\\n",
    "   9 & 4 & 8 & 0 & 5 \\\\\n",
    "   3 & 6 & 1 & 5 & 0 \\\\\n",
    "  \\end{matrix}\n",
    "  \\right]\n",
    "$$\n",
    "(Using the shortest distance as the distance between clusters)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Step 1: construct 5 clsuters and identify the two samples that have the least distance:\n",
    "$D_{35}$ or $D_{53}$ is the smallest, so sample 3 and sample 5 are arranged as the same cluster, $C_{6}$;\n",
    "- Step 2: calculate the distances between $C_{6}$ and other clusters:\n",
    "$D_{61} = 2, D_{62} = 5, D_{64} = 5$, whereas the distances between other clusters are: $D_{12} = 7, D_{14} = 9, D_{24} = 4$, therefore, $C_{6}$ and $C_{1}$ (that is, $C_{1}$, $C_{3}$, $C_{5}$) are arranged together to form $C_{7}$;\n",
    "- Step 3: calculate the distances between $C_{7}$ and other clusters:\n",
    "$D_{72} = 5, D_{74} = 5$, whereas the distances between other clusters are: $D_{24} = 4$, therefore, $C_{2}$ and $C_{4}$ are arranged together to form $C_{8}$;\n",
    "- Step 4: then $C_{7}$ and $C_{8}$ are arranged together as $C_{9}$ and the algorithm ends.\n",
    "![Alt text](images/3.2.2.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 4. Cluster distance meausures\n",
    "- Single link:\n",
    "$$ D(C_{1}, C_{2}) = \\min \\left\\{ {d_{ij}|x_{i} \\in C_{1}, x_{j} \\in C_{2}} \\right\\} $$\n",
    "- Complete link:\n",
    "$$ D(C_{1}, C_{2}) = \\max \\left\\{ {d_{ij}|x_{i} \\in C_{1}, x_{j} \\in C_{2}} \\right\\}$$\n",
    "- Average link: average of all pairwise distances\n",
    "$$ D(C_{1}, C_{2}) = \\sum_{x_{i} \\in C_{1}} \\sum_{x_{j} \\in C_{2}}{d_{ij}} $$\n",
    "- Centroids: distance between centroids in clusters\n",
    "$$ D(C_{1}, C_{2}) = d(c_{i}, c_{j}) $$\n",
    "- Ward's method: does the joining of two clusteres decrease the total distance from centroids:\n",
    "  - Before joining:\n",
    "  $$ TD = \\frac{1}{n_{i}}\\frac{1}{n_{j}}\\sum_{j=1}^k \\sum_{i=1}^n d(x_{i}, c_{j}) $$\n",
    "  - After joining:\n",
    "  $$ TD = \\sum_{i=1}^n d(x_{i}, c_{k}) $$\n",
    "- All of above distances can be expressed as:\n",
    "$$ D_{k,i+j} = \\alpha_{i} D_{k,i} + \\alpha_{j} D_{k,j} + \\beta D_{k,j} + \\gamma|D_{k,i}-D_{k,j}| $$\n",
    "![alt text](images/3.2.5.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}